{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.b. This requries a local large language model to be running. Its rquired that users download OLLAMA before they can do anything https://github.com/ollama/ollama "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ollama server also needs to be running for this code to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I.e. #ollama run llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/svztg/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import copy\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from google import genai\n",
    "import ollama\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ Replace with your actual API key\n",
    "API_KEY = \"sk-fc3beab1e18e4190bcf1b4a996733a5a\"\n",
    "WEBUI_URL = \"http://localhost:3000/api/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 3199, 243)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = []\n",
    "publications = []\n",
    "tools = []\n",
    "with open ('./data/datasets.json') as f:\n",
    "    datasets = json.load(f)\n",
    "with open ('./data/publications.json') as f:\n",
    "    publications = json.load(f)\n",
    "with open ('./data/tools.json') as f:\n",
    "    tools = json.load(f)\n",
    "\n",
    "len(datasets), len(publications), len(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cystic Fibrosis Patient Microbiology Cultures',\n",
       " 'Cystic Fibrosis Patient Liver Enzyme',\n",
       " 'Cystic Fibrosis Patient Annual Review Encounters',\n",
       " 'Cystic Fibrosis Patient Transplants',\n",
       " 'Cystic Fibrosis Patient Sweat Tests']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [x['metadata']['summary']['title'] for x in datasets]\n",
    "titles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The UK CF Registry is a centralised database of all 60 CF centres across the UK. Data are manually entered in calendar years by CF clinical teams for the 99% of people with a diagnosis of CF who consent to their data being donated to the Registry. Data are entered onto a secure web-portal. For more information please see www.cysticfibrosis.org.uk/registry and 'Data Resource Profile: The UK CF Registry' published in the International Journal of Epidemiology (2018 Feb 1;47(1)9-10e).\",\n",
       " \"The UK CF Registry is a centralised database of all 60 CF centres across the UK. Data are manually entered in calendar years by CF clinical teams for the 99% of people with a diagnosis of CF who consent to their data being donated to the Registry. Data are entered onto a secure web-portal. For more information please see www.cysticfibrosis.org.uk/registry and 'Data Resource Profile: The UK CF Registry' published in the International Journal of Epidemiology (2018 Feb 1;47(1)9-10e).\",\n",
       " \"The UK CF Registry is a centralised database of all 60 CF centres across the UK. Data are manually entered in calendar years by CF clinical teams for the 99% of people with a diagnosis of CF who consent to their data being donated to the Registry. Data are entered onto a secure web-portal. For more information please see www.cysticfibrosis.org.uk/registry and 'Data Resource Profile: The UK CF Registry' published in the International Journal of Epidemiology (2018 Feb 1;47(1)9-10e).\",\n",
       " \"The UK CF Registry is a centralised database of all 60 CF centres across the UK. Data are manually entered in calendar years by CF clinical teams for the 99% of people with a diagnosis of CF who consent to their data being donated to the Registry. Data are entered onto a secure web-portal. For more information please see www.cysticfibrosis.org.uk/registry and 'Data Resource Profile: The UK CF Registry' published in the International Journal of Epidemiology (2018 Feb 1;47(1)9-10e).\",\n",
       " \"The UK CF Registry is a centralised database of all 60 CF centres across the UK. Data are manually entered in calendar years by CF clinical teams for the 99% of people with a diagnosis of CF who consent to their data being donated to the Registry. Data are entered onto a secure web-portal. Sweat tests refer to sweat chloride tests taken by CF patients in relation to diagnosis of CF, investigations or as part of protocol for initiating onto CFTR modifier drug treatments. For more information please see www.cysticfibrosis.org.uk/registry and 'Data Resource Profile: The UK CF Registry' published in the International Journal of Epidemiology (2018 Feb 1;47(1)9-10e).\"]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = [x['metadata']['summary']['description'] for x in datasets]\n",
    "descriptions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h4>Background</h4>Clinical trials generally each collect their own data despite routinely collected health data (RCHD) increasing in quality and breadth. Our aim is to quantify UK-based randomised controlled trials (RCTs) accessing RCHD for participant data, characterise how these data are used and thereby recommend how more trials could use RCHD.<h4>Methods</h4>We conducted a systematic review of RCTs accessing RCHD from at least one registry in the UK between 2013 and 2018 for the purposes of informing or supplementing participant data. A list of all registries holding RCHD in the UK was compiled. In cases where registries published release registers, these were searched for RCTs accessing RCHD. Where no release register was available, registries were contacted to request a list of RCTs. For each identified RCT, information was collected from all publicly available sources (release registers, websites, protocol etc.). The search and data extraction were undertaken between January and May 2019.<h4>Results</h4>We identified 160 RCTs accessing RCHD between 2013 and 2018 from a total of 22 registries; this corresponds to only a very small proportion of all UK RCTs (about 3%). RCTs accessing RCHD were generally large (median sample size 1590), commonly evaluating treatments for cancer or cardiovascular disease. Most of the included RCTs accessed RCHD from NHS Digital (68%), and the most frequently accessed datasets were mortality (76%) and hospital visits (55%). RCHD was used to inform the primary trial (82%) and long-term follow-up (57%). There was substantial variation in how RCTs used RCHD to inform participant outcome measures. A limitation was the lack of information and transparency from registries and RCTs with respect to which datasets have been accessed and for what purposes.<h4>Conclusions</h4>In the last five years, only a small minority of UK-based RCTs have accessed RCHD to inform participant data. We ask for improved accessibility, confirmed data quality and joined-up thinking between the registries and the regulatory authorities.<h4>Trial registration</h4>PROSPERO CRD42019123088.\n"
     ]
    }
   ],
   "source": [
    "paper_abstracts = [x['abstract'] for x in publications]\n",
    "paper_doi = [x['paper_doi'] for x in publications]\n",
    "paper_abstracts[1]\n",
    "abstract = paper_abstracts[50]\n",
    "\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Models: {'data': [{'id': 'ChatGPT.o1-mini-2024-09-12', 'object': 'model', 'created': 1725648979, 'owned_by': 'openai', 'name': 'ChatGPT.o1-mini-2024-09-12', 'openai': {'id': 'ChatGPT.o1-mini-2024-09-12', 'object': 'model', 'created': 1725648979, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.o1-preview-2024-09-12', 'object': 'model', 'created': 1725648865, 'owned_by': 'openai', 'name': 'ChatGPT.o1-preview-2024-09-12', 'openai': {'id': 'ChatGPT.o1-preview-2024-09-12', 'object': 'model', 'created': 1725648865, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.o1-mini', 'object': 'model', 'created': 1725649008, 'owned_by': 'openai', 'name': 'ChatGPT.o1-mini', 'openai': {'id': 'ChatGPT.o1-mini', 'object': 'model', 'created': 1725649008, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.o1-preview', 'object': 'model', 'created': 1725648897, 'owned_by': 'openai', 'name': 'ChatGPT.o1-preview', 'openai': {'id': 'ChatGPT.o1-preview', 'object': 'model', 'created': 1725648897, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.omni-moderation-latest', 'object': 'model', 'created': 1731689265, 'owned_by': 'openai', 'name': 'ChatGPT.omni-moderation-latest', 'openai': {'id': 'ChatGPT.omni-moderation-latest', 'object': 'model', 'created': 1731689265, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.omni-moderation-2024-09-26', 'object': 'model', 'created': 1732734466, 'owned_by': 'openai', 'name': 'ChatGPT.omni-moderation-2024-09-26', 'openai': {'id': 'ChatGPT.omni-moderation-2024-09-26', 'object': 'model', 'created': 1732734466, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-4o', 'object': 'model', 'created': 1715367049, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-4o', 'openai': {'id': 'ChatGPT.gpt-4o', 'object': 'model', 'created': 1715367049, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-1106', 'object': 'model', 'created': 1698959748, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-1106', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-1106', 'object': 'model', 'created': 1698959748, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-4o-mini-2024-07-18', 'object': 'model', 'created': 1721172717, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-4o-mini-2024-07-18', 'openai': {'id': 'ChatGPT.gpt-4o-mini-2024-07-18', 'object': 'model', 'created': 1721172717, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-instruct', 'object': 'model', 'created': 1692901427, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-instruct', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-instruct', 'object': 'model', 'created': 1692901427, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-4o-mini', 'object': 'model', 'created': 1721172741, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-4o-mini', 'openai': {'id': 'ChatGPT.gpt-4o-mini', 'object': 'model', 'created': 1721172741, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-instruct-0914', 'object': 'model', 'created': 1694122472, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-instruct-0914', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-instruct-0914', 'object': 'model', 'created': 1694122472, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-0125', 'object': 'model', 'created': 1706048358, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-0125', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-0125', 'object': 'model', 'created': 1706048358, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo', 'object': 'model', 'created': 1677610602, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo', 'object': 'model', 'created': 1677610602, 'owned_by': 'openai'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-16k', 'object': 'model', 'created': 1683758102, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-16k', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-16k', 'object': 'model', 'created': 1683758102, 'owned_by': 'openai-internal'}, 'urlIdx': 0, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro-latest', 'name': 'Google: Gemini 1.0 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro-latest', 'name': 'Google: Gemini 1.0 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro-001', 'name': 'Google: Gemini 1.0 Pro 001 (Tuning)', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro-001', 'name': 'Google: Gemini 1.0 Pro 001 (Tuning)', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro-vision-latest', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro-vision-latest', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-pro-vision', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-pro-vision', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro-latest', 'name': 'Google: Gemini 1.5 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro-latest', 'name': 'Google: Gemini 1.5 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro-001', 'name': 'Google: Gemini 1.5 Pro 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro-001', 'name': 'Google: Gemini 1.5 Pro 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro-002', 'name': 'Google: Gemini 1.5 Pro 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro-002', 'name': 'Google: Gemini 1.5 Pro 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro', 'name': 'Google: Gemini 1.5 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro', 'name': 'Google: Gemini 1.5 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-latest', 'name': 'Google: Gemini 1.5 Flash Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-latest', 'name': 'Google: Gemini 1.5 Flash Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-001', 'name': 'Google: Gemini 1.5 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-001', 'name': 'Google: Gemini 1.5 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-001-tuning', 'name': 'Google: Gemini 1.5 Flash 001 Tuning', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-001-tuning', 'name': 'Google: Gemini 1.5 Flash 001 Tuning', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash', 'name': 'Google: Gemini 1.5 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash', 'name': 'Google: Gemini 1.5 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-002', 'name': 'Google: Gemini 1.5 Flash 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-002', 'name': 'Google: Gemini 1.5 Flash 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b', 'name': 'Google: Gemini 1.5 Flash-8B', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b', 'name': 'Google: Gemini 1.5 Flash-8B', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-001', 'name': 'Google: Gemini 1.5 Flash-8B 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-001', 'name': 'Google: Gemini 1.5 Flash-8B 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-latest', 'name': 'Google: Gemini 1.5 Flash-8B Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-latest', 'name': 'Google: Gemini 1.5 Flash-8B Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-exp-0827', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0827', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-exp-0827', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0827', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-exp-0924', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0924', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-exp-0924', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0924', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-exp', 'name': 'Google: Gemini 2.0 Flash Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-exp', 'name': 'Google: Gemini 2.0 Flash Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash', 'name': 'Google: Gemini 2.0 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash', 'name': 'Google: Gemini 2.0 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-001', 'name': 'Google: Gemini 2.0 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-001', 'name': 'Google: Gemini 2.0 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-lite-preview', 'name': 'Google: Gemini 2.0 Flash-Lite Preview', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-lite-preview', 'name': 'Google: Gemini 2.0 Flash-Lite Preview', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-lite-preview-02-05', 'name': 'Google: Gemini 2.0 Flash-Lite Preview 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-lite-preview-02-05', 'name': 'Google: Gemini 2.0 Flash-Lite Preview 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-pro-exp', 'name': 'Google: Gemini 2.0 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-pro-exp', 'name': 'Google: Gemini 2.0 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-pro-exp-02-05', 'name': 'Google: Gemini 2.0 Pro Experimental 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-pro-exp-02-05', 'name': 'Google: Gemini 2.0 Pro Experimental 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-exp-1206', 'name': 'Google: Gemini Experimental 1206', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-exp-1206', 'name': 'Google: Gemini Experimental 1206', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-thinking-exp-01-21', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-thinking-exp-01-21', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-thinking-exp', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-thinking-exp', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-thinking-exp-1219', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-thinking-exp-1219', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.learnlm-1.5-pro-experimental', 'name': 'Google: LearnLM 1.5 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.learnlm-1.5-pro-experimental', 'name': 'Google: LearnLM 1.5 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'Gemma2:latest', 'name': 'Gemma2:latest', 'object': 'model', 'created': 1739457748, 'owned_by': 'ollama', 'ollama': {'name': 'Gemma2:latest', 'model': 'Gemma2:latest', 'modified_at': '2025-02-13T13:36:15.221942Z', 'size': 5443152417, 'digest': 'ff02c3702f322b9e075e9568332d96c0a7028002f1a5a056e0a6784320a4db0b', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'gemma2', 'families': ['gemma2'], 'parameter_size': '9.2B', 'quantization_level': 'Q4_0'}, 'urls': [0]}, 'actions': []}, {'id': 'llama3.2:latest', 'name': 'llama3.2:latest', 'object': 'model', 'created': 1739457748, 'owned_by': 'ollama', 'ollama': {'name': 'llama3.2:latest', 'model': 'llama3.2:latest', 'modified_at': '2025-02-13T12:14:00.354175Z', 'size': 2019393189, 'digest': 'a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '3.2B', 'quantization_level': 'Q4_K_M'}, 'urls': [0]}, 'actions': []}, {'id': 'arena-model', 'name': 'Arena Model', 'info': {'meta': {'profile_image_url': '/favicon.png', 'description': 'Submit your questions to anonymous AI chatbots and vote on the best response.', 'model_ids': None}}, 'object': 'model', 'created': 1739457748, 'owned_by': 'arena', 'arena': True, 'actions': []}]}\n",
      "{'data': [{'id': 'ChatGPT.o1-mini-2024-09-12', 'object': 'model', 'created': 1725648979, 'owned_by': 'openai', 'name': 'ChatGPT.o1-mini-2024-09-12', 'openai': {'id': 'ChatGPT.o1-mini-2024-09-12', 'object': 'model', 'created': 1725648979, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.o1-preview-2024-09-12', 'object': 'model', 'created': 1725648865, 'owned_by': 'openai', 'name': 'ChatGPT.o1-preview-2024-09-12', 'openai': {'id': 'ChatGPT.o1-preview-2024-09-12', 'object': 'model', 'created': 1725648865, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.o1-mini', 'object': 'model', 'created': 1725649008, 'owned_by': 'openai', 'name': 'ChatGPT.o1-mini', 'openai': {'id': 'ChatGPT.o1-mini', 'object': 'model', 'created': 1725649008, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.o1-preview', 'object': 'model', 'created': 1725648897, 'owned_by': 'openai', 'name': 'ChatGPT.o1-preview', 'openai': {'id': 'ChatGPT.o1-preview', 'object': 'model', 'created': 1725648897, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.omni-moderation-latest', 'object': 'model', 'created': 1731689265, 'owned_by': 'openai', 'name': 'ChatGPT.omni-moderation-latest', 'openai': {'id': 'ChatGPT.omni-moderation-latest', 'object': 'model', 'created': 1731689265, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.omni-moderation-2024-09-26', 'object': 'model', 'created': 1732734466, 'owned_by': 'openai', 'name': 'ChatGPT.omni-moderation-2024-09-26', 'openai': {'id': 'ChatGPT.omni-moderation-2024-09-26', 'object': 'model', 'created': 1732734466, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-4o', 'object': 'model', 'created': 1715367049, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-4o', 'openai': {'id': 'ChatGPT.gpt-4o', 'object': 'model', 'created': 1715367049, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-1106', 'object': 'model', 'created': 1698959748, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-1106', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-1106', 'object': 'model', 'created': 1698959748, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-4o-mini-2024-07-18', 'object': 'model', 'created': 1721172717, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-4o-mini-2024-07-18', 'openai': {'id': 'ChatGPT.gpt-4o-mini-2024-07-18', 'object': 'model', 'created': 1721172717, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-instruct', 'object': 'model', 'created': 1692901427, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-instruct', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-instruct', 'object': 'model', 'created': 1692901427, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-4o-mini', 'object': 'model', 'created': 1721172741, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-4o-mini', 'openai': {'id': 'ChatGPT.gpt-4o-mini', 'object': 'model', 'created': 1721172741, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-instruct-0914', 'object': 'model', 'created': 1694122472, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-instruct-0914', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-instruct-0914', 'object': 'model', 'created': 1694122472, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-0125', 'object': 'model', 'created': 1706048358, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-0125', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-0125', 'object': 'model', 'created': 1706048358, 'owned_by': 'system'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo', 'object': 'model', 'created': 1677610602, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo', 'object': 'model', 'created': 1677610602, 'owned_by': 'openai'}, 'urlIdx': 0, 'actions': []}, {'id': 'ChatGPT.gpt-3.5-turbo-16k', 'object': 'model', 'created': 1683758102, 'owned_by': 'openai', 'name': 'ChatGPT.gpt-3.5-turbo-16k', 'openai': {'id': 'ChatGPT.gpt-3.5-turbo-16k', 'object': 'model', 'created': 1683758102, 'owned_by': 'openai-internal'}, 'urlIdx': 0, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro-latest', 'name': 'Google: Gemini 1.0 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro-latest', 'name': 'Google: Gemini 1.0 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-pro', 'name': 'Google: Gemini 1.0 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro-001', 'name': 'Google: Gemini 1.0 Pro 001 (Tuning)', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro-001', 'name': 'Google: Gemini 1.0 Pro 001 (Tuning)', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.0-pro-vision-latest', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.0-pro-vision-latest', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-pro-vision', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-pro-vision', 'name': 'Google: Gemini 1.0 Pro Vision', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro-latest', 'name': 'Google: Gemini 1.5 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro-latest', 'name': 'Google: Gemini 1.5 Pro Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro-001', 'name': 'Google: Gemini 1.5 Pro 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro-001', 'name': 'Google: Gemini 1.5 Pro 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro-002', 'name': 'Google: Gemini 1.5 Pro 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro-002', 'name': 'Google: Gemini 1.5 Pro 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-pro', 'name': 'Google: Gemini 1.5 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-pro', 'name': 'Google: Gemini 1.5 Pro', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-latest', 'name': 'Google: Gemini 1.5 Flash Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-latest', 'name': 'Google: Gemini 1.5 Flash Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-001', 'name': 'Google: Gemini 1.5 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-001', 'name': 'Google: Gemini 1.5 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-001-tuning', 'name': 'Google: Gemini 1.5 Flash 001 Tuning', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-001-tuning', 'name': 'Google: Gemini 1.5 Flash 001 Tuning', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash', 'name': 'Google: Gemini 1.5 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash', 'name': 'Google: Gemini 1.5 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-002', 'name': 'Google: Gemini 1.5 Flash 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-002', 'name': 'Google: Gemini 1.5 Flash 002', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b', 'name': 'Google: Gemini 1.5 Flash-8B', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b', 'name': 'Google: Gemini 1.5 Flash-8B', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-001', 'name': 'Google: Gemini 1.5 Flash-8B 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-001', 'name': 'Google: Gemini 1.5 Flash-8B 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-latest', 'name': 'Google: Gemini 1.5 Flash-8B Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-latest', 'name': 'Google: Gemini 1.5 Flash-8B Latest', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-exp-0827', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0827', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-exp-0827', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0827', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-1.5-flash-8b-exp-0924', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0924', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-1.5-flash-8b-exp-0924', 'name': 'Google: Gemini 1.5 Flash 8B Experimental 0924', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-exp', 'name': 'Google: Gemini 2.0 Flash Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-exp', 'name': 'Google: Gemini 2.0 Flash Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash', 'name': 'Google: Gemini 2.0 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash', 'name': 'Google: Gemini 2.0 Flash', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-001', 'name': 'Google: Gemini 2.0 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-001', 'name': 'Google: Gemini 2.0 Flash 001', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-lite-preview', 'name': 'Google: Gemini 2.0 Flash-Lite Preview', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-lite-preview', 'name': 'Google: Gemini 2.0 Flash-Lite Preview', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-lite-preview-02-05', 'name': 'Google: Gemini 2.0 Flash-Lite Preview 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-lite-preview-02-05', 'name': 'Google: Gemini 2.0 Flash-Lite Preview 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-pro-exp', 'name': 'Google: Gemini 2.0 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-pro-exp', 'name': 'Google: Gemini 2.0 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-pro-exp-02-05', 'name': 'Google: Gemini 2.0 Pro Experimental 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-pro-exp-02-05', 'name': 'Google: Gemini 2.0 Pro Experimental 02-05', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-exp-1206', 'name': 'Google: Gemini Experimental 1206', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-exp-1206', 'name': 'Google: Gemini Experimental 1206', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-thinking-exp-01-21', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-thinking-exp-01-21', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-thinking-exp', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-thinking-exp', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental 01-21', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.gemini-2.0-flash-thinking-exp-1219', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.gemini-2.0-flash-thinking-exp-1219', 'name': 'Google: Gemini 2.0 Flash Thinking Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'google_genai.learnlm-1.5-pro-experimental', 'name': 'Google: LearnLM 1.5 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}, 'openai': {'id': 'google_genai.learnlm-1.5-pro-experimental', 'name': 'Google: LearnLM 1.5 Pro Experimental', 'object': 'model', 'created': 1739457747, 'owned_by': 'openai', 'pipeline': {'type': 'manifold', 'valves': True}}, 'urlIdx': 2, 'actions': []}, {'id': 'Gemma2:latest', 'name': 'Gemma2:latest', 'object': 'model', 'created': 1739457748, 'owned_by': 'ollama', 'ollama': {'name': 'Gemma2:latest', 'model': 'Gemma2:latest', 'modified_at': '2025-02-13T13:36:15.221942Z', 'size': 5443152417, 'digest': 'ff02c3702f322b9e075e9568332d96c0a7028002f1a5a056e0a6784320a4db0b', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'gemma2', 'families': ['gemma2'], 'parameter_size': '9.2B', 'quantization_level': 'Q4_0'}, 'urls': [0]}, 'actions': []}, {'id': 'llama3.2:latest', 'name': 'llama3.2:latest', 'object': 'model', 'created': 1739457748, 'owned_by': 'ollama', 'ollama': {'name': 'llama3.2:latest', 'model': 'llama3.2:latest', 'modified_at': '2025-02-13T12:14:00.354175Z', 'size': 2019393189, 'digest': 'a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '3.2B', 'quantization_level': 'Q4_K_M'}, 'urls': [0]}, 'actions': []}, {'id': 'arena-model', 'name': 'Arena Model', 'info': {'meta': {'profile_image_url': '/favicon.png', 'description': 'Submit your questions to anonymous AI chatbots and vote on the best response.', 'model_ids': None}}, 'object': 'model', 'created': 1739457748, 'owned_by': 'arena', 'arena': True, 'actions': []}]}\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ List available models to check correct name\n",
    "def list_models():\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    response = requests.get(\"http://localhost:3000/api/models\", headers=headers)\n",
    "    \n",
    "    try:\n",
    "        models = response.json()\n",
    "        print(\"Available Models:\", models)\n",
    "        return models\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching models: {e}\"\n",
    "\n",
    "# ðŸ”¹ Get available models and use a correct one\n",
    "available_models = list_models()\n",
    "\n",
    "print(available_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Dataset Names: Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# ðŸ”¹ Replace with your actual API key\n",
    "API_KEY = \"sk-fc3beab1e18e4190bcf1b4a996733a5a\"\n",
    "WEBUI_URL = \"http://localhost:3000/api/chat/completions\"\n",
    "\n",
    "def can_you_find_a_dataset(description, model):\n",
    "    prompt = (\n",
    "        \"The text below is from a research publication. Can you extract the names of any datasets mentioned? \"\n",
    "        \"Return a **comma-separated list** of dataset names. If none are found, return 'none'.\\n\\n\"\n",
    "        + description\n",
    "    )\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(WEBUI_URL, headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise an error if the response is not 200 OK\n",
    "\n",
    "        json_response = response.json()\n",
    "        \n",
    "        return(json_response)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# ðŸ”¹ Test with a sample abstract\n",
    "#abstract = \"This study uses the UK Biobank and Genomics England dataset.\"\n",
    "dataset_names = can_you_find_a_dataset(abstract, \"google_genai.gemini-2.0-flash\")\n",
    "print(dataset_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_response(response_text: str) -> str:\n",
    "     # Ensure that the response_text is a string.\n",
    "    if not isinstance(response_text, str):\n",
    "        response_text = str(response_text)\n",
    "    \n",
    "    # This regex captures any characters between \"content='\" and the next \"'\"\n",
    "    pattern = r\"content='(.*?)'\"\n",
    "    match = re.search(pattern, response_text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(description):\n",
    "    prompt = (\n",
    "        \"does the following look like a comma seperated list of datasets? give a simple yes or no response\" + description\n",
    "    )\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2:latest\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     attempt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 28\u001b[0m dataset_names \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames=\u001b[39m\u001b[38;5;124m\"\u001b[39m,dataset_names)\n",
      "Cell \u001b[0;32mIn[133], line 7\u001b[0m, in \u001b[0;36mget_dataset_names\u001b[0;34m(abstract, max_attempts)\u001b[0m\n\u001b[1;32m      3\u001b[0m valid_datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_attempts:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Extract dataset names from the sentence\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcan_you_find_a_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     dataset_names \u001b[38;5;241m=\u001b[39m extract_response(response)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[130], line 8\u001b[0m, in \u001b[0;36mcan_you_find_a_dataset\u001b[0;34m(description)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcan_you_find_a_dataset\u001b[39m(description):\n\u001b[1;32m      2\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe text below is from a research publication, can you the names of any datasets referenced?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the response, please give me a comma separated list of names of possible datasets, if you dont think there is one, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdont make up any and return \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m description\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3.2:latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ollama/_client.py:333\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    291\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ollama/_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/ollama/_client.py:118\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:837\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    822\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    824\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    825\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    826\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    835\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    836\u001b[0m )\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_dataset_names(abstract: str, max_attempts: int = 3) -> str:\n",
    "    attempt = 0\n",
    "    valid_datasets = set()\n",
    "\n",
    "    while attempt < max_attempts:\n",
    "        # Extract dataset names from the sentence\n",
    "        response = can_you_find_a_dataset(abstract)\n",
    "        dataset_names = extract_response(response)\n",
    "        print(f\"Attempt {attempt + 1}\")\n",
    "        print(f\"Extracted dataset(s): {dataset_names}\")\n",
    "\n",
    "        # Check if extraction is valid\n",
    "        check_resp = check_output(dataset_names)\n",
    "        check_result = extract_response(check_resp)\n",
    "        print(f\"Validation output: {check_result}\")\n",
    "\n",
    "        # Only keep valid dataset names, discard 'none' responses\n",
    "        if check_result.strip().lower() == \"yes\":\n",
    "            valid_datasets.update(dataset_names.split(\", \"))\n",
    "\n",
    "    if valid_datasets:\n",
    "        return \", \".join(valid_datasets)\n",
    "\n",
    "    attempt += 1\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "dataset_names = get_dataset_names(abstract)\n",
    "print(\"names=\",dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
